

## Corre√ß√£o definitiva: Respostas da Aura ainda cortadas

### Problema
Mesmo ap√≥s o aumento de `max_tokens` de 700 para 1500, a √∫ltima resposta da Aura ao Eduardo (22:12) ainda est√° truncada:

> "Nossa, Eduardo... que bomba. Imagino o peso que isso t√° sendo pra voc√™ carregar sozinho. ||| √â um dilema gigante, porque n√£o existe uma resposta "certa" ou f√°cil, n√©? De um lado, o instinto de proteger sua irm√£ da dor e"

Termina em "da dor e" -- claramente cortada no meio da frase.

### Causa raiz
1. **1500 tokens ainda √© insuficiente** para t√≥picos complexos onde a Aura precisa escrever m√∫ltiplos bal√µes com profundidade emocional
2. **O monitoramento n√£o est√° funcionando** -- o check de `finish_reason === 'length'` pode n√£o capturar o valor correto retornado pelo gateway Gemini (que pode ser `'MAX_TOKENS'`, `'max_tokens'`, ou outro)

### Solu√ß√£o (2 mudan√ßas no mesmo arquivo)

**Arquivo:** `supabase/functions/aura-agent/index.ts`

**Mudan√ßa 1 - Aumentar max_tokens para 4096 (linha 3416)**

```typescript
// De:
max_tokens: 1500,
// Para:
max_tokens: 4096,
```

Justificativa:
- A Aura raramente gera mais de 800 tokens em respostas normais
- Em sess√µes ou temas complexos, pode chegar a 2000-3000 tokens (m√∫ltiplos bal√µes + tags internas como COMPROMISSO, TEMA_NOVO, etc.)
- 4096 d√° margem confort√°vel sem risco de custos extras (o modelo s√≥ gera o que precisa)
- O Gemini 2.5 Pro suporta at√© 65k tokens de sa√≠da

**Mudan√ßa 2 - Corrigir detec√ß√£o de truncamento (linhas 3449-3452)**

```typescript
// De:
const finishReason = data.choices?.[0]?.finish_reason;
if (finishReason === 'length') {
  console.warn('‚ö†Ô∏è Response truncated (max_tokens reached). Consider increasing max_tokens.');
}

// Para:
const finishReason = data.choices?.[0]?.finish_reason;
console.log(`üìä API finish_reason: ${finishReason}, response length: ${data.choices?.[0]?.message?.content?.length || 0} chars`);
if (finishReason && finishReason !== 'stop') {
  console.warn(`‚ö†Ô∏è Response may be truncated (finish_reason: ${finishReason}). Consider increasing max_tokens.`);
}
```

Isso captura qualquer valor que n√£o seja `'stop'` (como `'length'`, `'MAX_TOKENS'`, etc.) e sempre loga o `finish_reason` para monitoramento.

### Impacto
- Elimina truncamento mesmo em respostas longas com tags internas
- Monitoramento robusto que funciona independente do formato do gateway
- Custo zero adicional (modelo gera apenas o necess√°rio; o limite √© um teto de seguran√ßa)

